{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_for_Direct_Imaging.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycdhGJKJ0OQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "#tf.enable_eager_execution()\n",
        "from PIL import Image\n",
        "from astropy.io import fits\n",
        "import glob\n",
        "import scipy\n",
        "from scipy import signal\n",
        "import cv2\n",
        "\n",
        "\n",
        "from IPython import display\n",
        "class data_for_GAN():\n",
        "    def __init__(self):\n",
        "                \n",
        "        self.train_images = []\n",
        "        self.train_images_raw=[]\n",
        "        itera=0\n",
        "        for filename in glob.glob('Artificial-Intelligence//Direct Imaging//Data//comtemp_flats-DD2//temp//*.fits'):\n",
        "            #print('alpha')\n",
        "            #fits.info(filename)\n",
        "            self.train_images_raw.append(fits.getdata(filename))\n",
        "               \n",
        "            \n",
        "            itera=itera+1\n",
        "            if itera%100==0:\n",
        "                print(iter)\n",
        "        train_images = (np.array(self.train_images_raw) - 127.5) / 127.5\n",
        "        print(np.shape(train_images))\n",
        "        for ite in range(0,len(train_images)):\n",
        "            custom_image_data=self.crop_custom(np.squeeze(train_images[ite,:,:]))\n",
        "            if np.min(custom_image_data)!=np.max(custom_image_data): \n",
        "               self.train_images.append(custom_image_data)\n",
        "               plt.imshow(custom_image_data)\n",
        "               plt.axis('off')\n",
        "               fig_name='Artificial-Intelligence//Direct Imaging//Data//comtemp_flats-DD2//temp//non_planetary_image_data//image_'+str(ite)+'_'+'.png'\n",
        "               plt.savefig(fig_name)\n",
        "               plt.close()\n",
        "        \n",
        "        for ite in range(0,len(self.train_images)):\n",
        "            theta=np.int(np.round(np.random.randint(0,180),2))\n",
        "            self.planetary_injection(self.train_images[ite],theta,ite)  \n",
        "        self.planetary_image_data=[]\n",
        "        itera=0\n",
        "        '''\n",
        "        for filename in glob.glob('Artificial-Intelligence//Direct Imaging//Data//comtemp_flats-DD2//temp//planetary_image_data//*.png'):\n",
        "            \n",
        "            planetary_images_raw = cv2.imread(filename)\n",
        "            planetary_images_raw_crop = cv2.resize(planetary_images_raw, dsize=(28,28), interpolation=cv2.INTER_CUBIC)\n",
        "            planetary_image = (np.array(planetary_images_raw_crop) - 127.5) / 127.5\n",
        "            self.planetary_image_data.append(planetary_image)\n",
        "            #print(itera)\n",
        "            itera=itera+1\n",
        "        '''\n",
        "        \n",
        "    def planetary_injection(self,image,theta,ite):\n",
        "        im=self.gkern(10)\n",
        "        fig=plt.figure(figsize=(10,10))\n",
        "        plt.axis('off')\n",
        "        rad=0.3\n",
        "        plt.imshow(image)\n",
        "        Px=0.5+rad*np.cos(theta*np.pi/180)\n",
        "        Py=0.5+rad*np.sin(theta*np.pi/180)\n",
        "        #print(Px,Py)\n",
        "        newax = fig.add_axes([Px,Py, 0.02, 0.02])\n",
        "        newax.imshow((im),interpolation='none')\n",
        "        newax.axis('off')\n",
        "        fig_name='Artificial-Intelligence//Direct Imaging//Data//comtemp_flats-DD2//temp//planetary_image_data//image_'+str(ite)+'_'+'.png'\n",
        "        plt.savefig(fig_name)\n",
        "        #print(ite)\n",
        "        plt.close()\n",
        "      \n",
        "    def gkern(self,kernlen=21, std=3):\n",
        "        \"\"\"Returns a 2D Gaussian kernel array.\"\"\"\n",
        "        #print('#')\n",
        "        gkern1d = signal.gaussian(kernlen, std=std).reshape(kernlen, 1)\n",
        "        gkern2d = np.outer(gkern1d, gkern1d)\n",
        "        return gkern2d\n",
        "\n",
        "       \n",
        "\n",
        "    def crop_custom(self,image,resize_w=28):\n",
        "        \n",
        "        i = int(73-32)\n",
        "        j = int(212-32)\n",
        "        crop_h=64\n",
        "        crop_w=64\n",
        "        \n",
        "        New_Image=Image.fromarray(image[j:j+crop_h, i:i+crop_w]).resize(size=[resize_w, resize_w])\n",
        "        New_Image_Conversion=New_Image.convert('L')\n",
        "        return np.asarray(New_Image_Conversion)\n",
        "        \n",
        "class GAN():\n",
        "    def __init__(self,obj):\n",
        "        super().__init__()\n",
        "        self.cross_entropy=tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "        self.generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "        self.discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "        self.BUFFER_SIZE = 100\n",
        "        self.BATCH_SIZE = 25\n",
        "        self.EPOCHS = 15000\n",
        "        self.noise_dim = 100\n",
        "        self.num_examples_to_generate = 16\n",
        "        self.seed = tf.random.normal([self.num_examples_to_generate, self.noise_dim])\n",
        "        self.train_dataset = tf.data.Dataset.from_tensor_slices(obj.train_images).shuffle(self.BUFFER_SIZE).batch(self.BATCH_SIZE)\n",
        "\n",
        "        self.generator=self.make_generator_model()\n",
        "        self.discriminator=self.make_discriminator_model() \n",
        "    \n",
        "    def make_generator_model(self):\n",
        "        model = tf.keras.Sequential()\n",
        "        model.add(layers.Dense(7*7*64, use_bias=False, input_shape=(100,)))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.LeakyReLU())\n",
        "\n",
        "        model.add(layers.Reshape((7,7, 64)))\n",
        "        assert model.output_shape == (None, 7, 7, 64) # Note: None is the batch size\n",
        "\n",
        "        model.add(layers.Conv2DTranspose(32, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "        assert model.output_shape == (None, 7, 7, 32)\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.LeakyReLU())\n",
        "\n",
        "        model.add(layers.Conv2DTranspose(16, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "        assert model.output_shape == (None, 14, 14, 16)\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.LeakyReLU())\n",
        "\n",
        "        #model.add(layers.Conv2DTranspose(1, (5, 5), strides=(4, 4), padding='same', use_bias=False))\n",
        "        #assert model.output_shape == (None, 28, 28, 1)\n",
        "        model.add(layers.Conv2DTranspose(1, (2, 2), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "\n",
        "        return model\n",
        "    \n",
        "    def make_discriminator_model(self):\n",
        "        model = tf.keras.Sequential()\n",
        "        model.add(layers.Conv2D(32, (5, 5), strides=(2, 2), padding='same',\n",
        "                                         input_shape=[28, 28, 1]))\n",
        "        model.add(layers.LeakyReLU())\n",
        "        model.add(layers.Dropout(0.3))\n",
        "\n",
        "        model.add(layers.Conv2D(16, (5, 5), strides=(2, 2), padding='same'))\n",
        "        model.add(layers.LeakyReLU())\n",
        "        model.add(layers.Dropout(0.3))\n",
        "\n",
        "        #model.add(layers.Conv2D(16, (5, 5), strides=(4, 4), padding='same'))\n",
        "        #model.add(layers.LeakyReLU())\n",
        "        #model.add(layers.Dropout(0.3))\n",
        "\n",
        "        \n",
        "\n",
        "        model.add(layers.Flatten())\n",
        "        model.add(layers.Dense(1))\n",
        "\n",
        "        return model\n",
        "    \n",
        "    def discriminator_loss(self,real_output, fake_output):\n",
        "        real_loss = self.cross_entropy(tf.ones_like(real_output), real_output)\n",
        "        fake_loss = self.cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "        total_loss = real_loss + fake_loss\n",
        "        return total_loss\n",
        "\n",
        "    def generator_loss(self,fake_output):\n",
        "        return self.cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "    \n",
        "    #@tf.function\n",
        "    def train_step(self,images):\n",
        "        noise = tf.random.normal([self.BATCH_SIZE, self.noise_dim])\n",
        "\n",
        "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "          generated_images = self.generator(noise, training=True)\n",
        "\n",
        "          real_output = self.discriminator(images, training=True)\n",
        "          fake_output = self.discriminator(generated_images, training=True)\n",
        "\n",
        "          gen_loss = self.generator_loss(fake_output)\n",
        "          disc_loss = self.discriminator_loss(real_output, fake_output)\n",
        "\n",
        "        gradients_of_generator = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
        "        gradients_of_discriminator = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
        "\n",
        "        self.generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "        self.discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "        self.generator_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n",
        "        self.discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n",
        "    \n",
        "    def generate_and_save_images(self,model, epoch, test_input):\n",
        "        \n",
        "        predictions = model(test_input, training=False)\n",
        "\n",
        "        fig = plt.figure(figsize=(4,4))\n",
        "\n",
        "        for i in range(predictions.shape[0]):\n",
        "            plt.subplot(4, 4, i+1)\n",
        "            plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5)\n",
        "            plt.axis('off')\n",
        "\n",
        "        plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "        plt.show()\n",
        "    \n",
        "    \n",
        "    def center_crop_custom(x,resize_w=256):\n",
        "        \n",
        "        h, w = x.shape[:2]\n",
        "        i = int(73-32)\n",
        "        j = int(212-32)\n",
        "        crop_h=64\n",
        "        crop_w=64\n",
        "        return scipy.misc.imresize(x[j:j+crop_h, i:i+crop_w],\n",
        "                                  [resize_w, resize_w])\n",
        "\n",
        "    def train(self):\n",
        "          checkpoint = tf.train.Checkpoint(generator_optimizer=self.generator_optimizer,\n",
        "                                 discriminator_optimizer=self.discriminator_optimizer,\n",
        "                                 generator=self.generator,\n",
        "                                 discriminator=self.discriminator)\n",
        "          checkpoint_dir = './training_checkpoints'\n",
        "          checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "          \n",
        "          status = checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "          for epoch in range(self.EPOCHS):\n",
        "            start = time.time()\n",
        "\n",
        "            for image_batch in self.train_dataset:\n",
        "                self.train_step(image_batch)\n",
        "\n",
        "            # Produce images for the GIF as we go\n",
        "                display.clear_output(wait=True)\n",
        "                self.generate_and_save_images(self.generator,\n",
        "                                         epoch + 1,\n",
        "                                         self.seed)\n",
        "\n",
        "            # Save the model every 15 epochs\n",
        "            \n",
        "            if (epoch + 1) % 15 == 0:\n",
        "              checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "              print(epoch)\n",
        "\n",
        "            \n",
        "          display.clear_output(wait=True)\n",
        "          \n",
        "          self.generate_and_save_images(self.generator,\n",
        "                                       epoch,\n",
        "                                       self.seed)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}